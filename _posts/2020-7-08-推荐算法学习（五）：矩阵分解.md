---
published: true
title: 推荐算法学习（五）：评分预测&矩阵分解
category: 推荐算法
tags: 
  - 评分预测
  - 矩阵分解
  - EVD
  - SVD
  - Surprise
  - Google Colab
layout: post
---

推荐系统的两大应用场景分别是**评分预测**（Rating Prediction）和**Top-N推荐**（Item Ranking）。其中评分预测主要用于评价网站，比如用户给自己看过的电影评多少分，或者用户给自己看过的书籍评价多少分，**矩阵分解**技术主要应用于评分预测问题；Top-N推荐常用于购物网站或拿不到显式评分的网站，通过用户的隐式反馈为用户提供一个可能感兴趣的Item列表，此排序任务需要排序模型进行建模。本文主要介绍如何利用矩阵分解来解决评分预测问题。

## 矩阵分解概述

在之前的文章中，我们介绍过常用的推荐算法，其中协同过滤是推荐系统的主流思想之一。协同过滤技术可划分为基于内存/邻域的协同过滤（Memory-based CF）与**基于模型的协同过滤**技术（Model-based CF）。这里基于模型的协同过滤技术中矩阵分解（Matrix Factorization，MF）技术最为普遍和流行，因为它的可扩展性好并且易于实现。 

矩阵分解是一种**隐语义模型**。隐语义模型是通过隐含特征（Latent Factor）联系用户兴趣和物品，基于用户行为的自动聚类。在评分预测问题中，收集到的用户行为评分数据可用一个评分矩阵表示，矩阵分解要做的是预测出评分矩阵中缺失的评分，使得预测评分能反映用户的喜欢程度，从而可以把预测评分最高的前K个电影推荐给用户。为了预测缺失的评分，矩阵分解学习User矩阵和Item矩阵，使得User矩阵*Item矩阵与评分矩阵中已知的评分差异最小，此时评分预测问题转化为了一个最优化问题，求解该最优化问题即可将评分矩阵分解成User矩阵和Item矩阵，从而可以计算出缺失的评分。

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/0.png" alt="0" style="zoom:70%;" />



以电影评分预测为例，用评分矩阵表示收集到的用户行为数据，12个用户，9部电影。

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/1.png" alt="0" style="zoom:60%;" />

观察下图User矩阵，可知用户的观影爱好体现在User向量上，观察Item矩阵，可知电影的风格体现在Item向量上，MF用user向量和item向量的内积去拟合评分矩阵中该user对该item的评分，内积的大小反映了user对item的喜欢程度，内积大喜欢程度高，反之喜欢程度低。这里“动作”、“动画”、“爱情”为隐含特征，隐含特征个数k越大，隐类别分得越细，计算量越大。

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/2.png" alt="0" style="zoom:150%;" />

把这两个矩阵相乘，就能预测每个用户对每部电影的预测评分了，评分值越大，表示用户喜欢该电影的可能性越大，该电影就越值得推荐给用户。

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/3.png" alt="0" style="zoom:60%;" />

接下来我们将介绍矩阵分解的目标函数及目标函数最优化问题的求解，并梳理推荐系统中出现过的经典的矩阵分解方法。

## 矩阵分解目标函数

$r_{ui}$表示用户$u$对Item $i$ 的评分，当 $r_{ui}$>0时，表示有评分，当$r_{ui}$=0时，表示没有评分；$x_u$表示用户$u$ 的向量，k维列向量；$y_i$表示Item $i$ 的向量，k维列向量；用户矩阵X，用户数为N，$X=[x_1,x_2,...,x_N]$；商品矩阵Y，商品数为M，$Y=[y_1,y_2,...,y_M]$.

用户向量与物品向量的内积，表示用户u 对物品i 的预测评分矩阵的目标函数：

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/4.png" alt="0" style="zoom:40%;" />

上式前半部分表示的是User矩阵*Item矩阵与评分矩阵中已知的评分差异，后半部分是L2正则项，保证数值计算稳定性，防止过拟合。

## 矩阵分解目标函数最优化问题求解

上述目标函数最优化问题的工程解法一般采用交替最小二乘法或随机梯度下降。

###　交替最小二乘法ALS

交替最小二乘法步骤：

* Step1，固定Y 优化X

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/5.png" alt="0" style="zoom:40%;" />

将目标函数转化为矩阵表达形式

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/6.png" alt="0" style="zoom:40%;" />

其中<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/7.png" alt="0" style="zoom:35%;" />，表示用户u对m个物品的评分；<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/8.png" alt="0" style="zoom:35%;" />为m个物品的向量。

对目标函数$J$关于$x_u$求梯度，并令梯度为零，得到：

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/9.png" alt="0" style="zoom:40%;" />

求解后可得：

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/10.png" alt="0" style="zoom:40%;" />

* Step2，固定X 优化Y

* 重复Step1和2，直到X和Y收敛，每次固定一个矩阵，优化另一个矩阵，都是**最小二乘问题**

除了针对**显式评分矩阵**，ALS还可以对**隐式矩阵**进行分解，将评分看成行为的强度，比如浏览次数，阅读时间等。当 $r_{ui}$>0时，表示用户u对商品i有行为，当$r_{ui}$=0时，表示用户u对商品i没有行为。

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/11.png" alt="0" style="zoom:40%;" />

上式 $p_{ui}$称为**用户偏好**：当用户u对物品i有过行为，认为用户u对物品i感兴趣，$p_{ui}$=1；当用户u对物品i没有过行为，认为用户u对物品i不感兴趣，$p_{ui}$=0.

对隐式矩阵进行分解的步骤：

* 引入置信度：<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/12.png" alt="0" style="zoom:35%;" />

当 $r_{ui}$>0时，$c_{ui}$与$r_{ui}$线性递增；当$r_{ui}$=0时，$c_{ui}$=1，也就是$c_{ui}$最小值为1.

* 目标函数

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/13.png" alt="0" style="zoom:40%;" />

* 利用ALS求解

**ALS工具**：

* spark mllib库
* spark ml库（官方推荐）
* Python代码：https://github.com/tushushu/imylu/blob/master/imylu/recommend/als.py

### 随机梯度下降SGD

SGD基本思路是以随机方式遍历训练集中的数据，并给出每个已知评分的预测评分。用户和物品特征向量的调整就沿着评分误差越来越小的方向迭代进行，直到误差达到要求。所以，SGD不需要遍历所有的样本即可完成特征向量的求解。

梯度下降法：

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/14.png" alt="0" style="zoom:40%;" />

其中 $\theta$为参数，代表权重，n为特征数用它来模拟y，需要最小化损失函数

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/15.png" alt="0" style="zoom:40%;" />

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/16.png" alt="0" style="zoom:90%;" />

* 我们处于山中的某个位置，不知道极值点在哪里
* 每一步，我们都以下降最多的路线来下山

$\alpha$表示学习率（步长），<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/17.png" alt="0" style="zoom:35%;" />（沿着梯度的反方向，即采用梯度下降的方式进行权重更新）

梯度下降更新过程：

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/18.png" alt="0" style="zoom:40%;" />

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/19.png" alt="0" style="zoom:45%;" />

* 批量梯度下降：在每次更新时用所有样本；稳定，收敛慢
* 随机梯度下降：每次更新时用1个样本，用1个样本来近似所有的样本；更快收敛，最终解在全局最优解附近
* mini-batch梯度下降：每次更新时用b个样本，折中方法；速度较快

## 矩阵分解方法

矩阵分解就是将矩阵拆解为多个矩阵的乘积。本文将介绍特征分解EVD和奇异值分解SVD两种分解方法，并介绍推荐系统中常见的矩阵分解算法。

### 特征/谱分解EVD

特征分解是将矩阵分解为特征值和特征向量表示的矩阵之积的方法，也称为谱分解。

 A是NxN维的**方阵**，对矩阵 A 进行特征分解：

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/25.png" alt="0" style="zoom:40%;" />

其中U的列向量是A的特征向量，Λ是对角矩阵，对角元素是特征向量的特征值。

如果A**对称方阵**，那么<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/26.png" alt="0" style="zoom:40%;" />

### 奇异值分解SVD

什么是SVD

SVD的作用：降维；SVD在推荐系统中的作用

#### FunkSVD算法



#### BiasSVD算法



#### SVD++算法



## 推荐系统工具：Surprise

常用的推荐系统库有Surprise和LightFM。Surprise是scikit系列中的一个推荐系统库；LightFM是一个Python推荐算法库，具有隐式和显式反馈的多种推荐算法实现，且易用、快速（通过多线程模型估计），能够产生高质量的结果。Surprise中涵盖了Baseline、基于邻域的协同过滤、矩阵分解（SVD，SVD++，PMF，NMF）、SlopeOne 协同过滤等常用推荐算法。Surprise中的评价指标包含**均方根误差（RMSE）、平均绝对误差（MAE）以及一致对的分数（FCP）**。接下来简单介绍Surprise中的Baseline算法和SlopeOne算法。

### Baseline算法

Baseline算法（基于统计的基准预测线打分）假设训练数据为：  <user, item, rating>三元组， 其中user为用户id， item为物品id，rating为user对item的投票分数， 其中用户u对物品i的真实投票分数我们记为$r_{ui}$，基线模型预估分数为$b_{ui}$，则可建模：

$$b_{ui}=\mu+b_u+b_i$$                                                              

其中$\mu$为所有已知评分数据的均值，$b_u$为用户的打分相对于平均值的偏差（如果某用户比较苛刻，打分都相对偏低， 则$b_u$会为负值；相反，如果某用户经常对很多片都打正分， 则$b_u$为正值）； $b_i$为该item被打分时，相对于平均值的偏差，可反映电影受欢迎程度。 该模型虽然简单， 但其中其实已经包含了用户个性化和item的个性化信息， 而且特别简单。

基线模型中，$\mu$可以通过统计得到，为了估计$b_u$和$b_i$，我们的目标函数可以写成：

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/20.png" alt="0" style="zoom:100%;" />

使用ALS优化该目标函数步骤：

* Step1，固定$b_u$，优化$b_i$
* Step2，固定$b_i$，优化$b_u$
* 重复Step1和2，直到收敛

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/21.png" alt="0" style="zoom:100%;" />

### SlopeOne算法

SlopeOne算法是由Daniel Lemire在2005年提出的一个Item-Based 的协同过滤推荐算法，最大优点在于算法很简单，易于实现，效率高且推荐准确度较高。其步骤为：

* Step1，计算Item之间的评分差的均值，记为评分偏差（两个item都评分过的用户）

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/22.png" alt="0" style="zoom:100%;" />

* Step2，根据Item间的评分偏差和用户的历史评分，预测用户对未评分的item的评分

<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/23.png" alt="0" style="zoom:100%;" />** **<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（五）/24.png" alt="0" style="zoom:100%;" />

* Step3，将预测评分排序，取topN对应的item推荐给用户

SlopeOne算法存在一个明显的问题是，如果有100个用户对Item1和Item2都打过分, 有1000个用户对Item3和Item2也打过分，显然这两个rating差的权重是不一样的，因此又提出了 Weighted Slope One算法，引入了权重对SlopeOne算法进行修正。

从上述内容不难看出，SlopeOne适用于item更新不频繁，且item数远小于user数的推荐场景，其依赖用户行为，也存在冷启动和稀疏性等问题。

## 【两章作业】实例1：使用PageRank分析希拉里邮箱丑闻关键人物

* **数据集**：<https://github.com/cystanford/PageRank>（希拉里邮件丑闻），包含了9306封邮件和513个人名

(1) Emails.csv：记录了所有公开邮件的内容，发送者和接受者的信息。

(2) Persons.csv：统计了邮件中所有人物的姓名及对应的ID。

(3) Aliases.csv：因为姓名存在别名的情况，为了将邮件中的人物进行统一，我们还需要用Aliases文件来查询别名和人物的对应关系。

* 将希拉里邮箱丑闻中人物看作节点，人物间发邮件关系看作边，设置边权重为发邮件的次数，如此生成的网络图如下<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（四）/7.png" alt="0" style="zoom:70%;" />

上图由于涉及人物众多、关系复杂，无法清晰的呈现邮箱丑闻中的关键人物。

* 计算每个节点（人物）的影响力（PR值），设置阈值，筛选出大于阈值的核心节点，绘制核心节点网络图如下<img src="https://raw.githubusercontent.com/Alice1214/alice1214.github.io/master/_posts/image/推荐算法（四）/8.png" alt="0" style="zoom:70%;" />

上图便能清晰明了的展现希拉里邮箱丑闻中关键人物及其之间的关系。

## 实例2：使用TextRank对新闻进行关键词提取及摘要输出

* **数据集**：news.txt

* **使用textrank4zh工具包，运用TextRank算法提取了新闻的关键词和关键句子（摘要）。**

>代码：<https://github.com/Alice1214/RS/blob/master/RS04/textrank_news.ipynb>

